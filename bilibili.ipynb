{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> 视频播放量预测：多种特征的综合分析</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1 案例目标**\n",
    "\n",
    "如何利用视频的封面与标题建立模型预测视频播放量。我们希望训练一个模型，使得当我们输入视频的封面和标题后，模型能输出预测的视频播放量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **2 基本思路**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的思路是：\n",
    "\n",
    "- （1）将视频封面图片经过迁移学习，变成一个图像特征X向量；\n",
    "\n",
    "具体而言将封面图片输入模型后，经过卷积神经网络（砍掉全连接层后的）进行图片特征的提取，得到图像特征X\n",
    "\n",
    "- （2）将标题文本通过编码处理，变成一个文本特征X向量；\n",
    "\n",
    "使用Tokenizer对标题文本进行编码处理，得到文本特征X\n",
    "\n",
    "- （3）将播放量作为Y向量，基于X，Y，建立一个LSTM回归模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 案例背景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "哔哩哔哩（简称B站），从最初围绕ACG文化的视频网站到现在开辟了20多个视频分区的文化娱乐社区，它不断成长演变并吸引了无数年轻人聚集于此，目前平均月度活跃用户已超过2亿。\n",
    "对于B站上的视频创作者（UP主）而言，高播放量的视频除了能收获众多粉丝外，还能够吸引广告商与之合作从而变现。因此，提高视频的播放量至关重要。严格来说，视频的播放量受诸多因素的影响：从稿件自身来看，有封面与标题的吸引度、内容质量等因素；从传播角度，有观众分享次数、用户是否关注该UP主甚至B站自身推荐系统等因素。\n",
    "\n",
    "<div>\n",
    "<img src = \"https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fi0.hdslb.com%2Fbfs%2Farticle%2F644819b882a576bb4cb91866d870a71f269719f8.png&refer=http%3A%2F%2Fi0.hdslb.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1648194290&t=5dcfe9acad3ac020b16bc90cdc63f1dd\">\n",
    "</div>\n",
    "\n",
    "在所有影响因素中，封面与标题是影响播放量的最重要因素之一。一方面，用户进入B站后映入眼帘的首先是视频与封面，而一个视频的标题和封面往往直接影响用户是否点击此视频；另一方面，其他因素如用户分享次数和推荐系统是否推荐与视频发布后第一批观众是否点击播放有关，而第一批观众是否点击播放同样与封面和标题是否吸引人有很大关系。因此，本案例选择分别根据视频的封面与标题对播放量进行预测。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 数据展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Images', 'master.csv', '.ipynb_checkpoints']\n",
      "74185\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('data'))                          #展示数据目录结构\n",
    "img_list=os.listdir('data/Images/')                #所有分析用图片文件名\n",
    "N=len(img_list); print(N)                          #图片总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>title</th>\n",
       "      <th>follower</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208204291</td>\n",
       "      <td>富奶奶vs穷奶奶/奶奶大战!</td>\n",
       "      <td>25907</td>\n",
       "      <td>5864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208212579</td>\n",
       "      <td>兄弟才是隐藏的boss啊</td>\n",
       "      <td>22</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>208215972</td>\n",
       "      <td>你到底说还是不说…</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>208219537</td>\n",
       "      <td>中国朋友教了我一句话：无事献殷勤，非奸即盗。</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208237322</td>\n",
       "      <td>如果你是大学里唯一的美人鱼！潜伏技巧！</td>\n",
       "      <td>25907</td>\n",
       "      <td>6357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74180</th>\n",
       "      <td>890997016</td>\n",
       "      <td>吃我邪神酱飞T</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74181</th>\n",
       "      <td>890997066</td>\n",
       "      <td>《和暗恋女神的厕所之情》</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74182</th>\n",
       "      <td>890997085</td>\n",
       "      <td>串哥和秀文一起连麦选妃</td>\n",
       "      <td>116</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74183</th>\n",
       "      <td>890997096</td>\n",
       "      <td>我又双叒叕来了</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74184</th>\n",
       "      <td>890997102</td>\n",
       "      <td>丈母娘啊，还是你最疼我啊！</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74185 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aid                   title  follower  view\n",
       "0      208204291          富奶奶vs穷奶奶/奶奶大战!     25907  5864\n",
       "1      208212579            兄弟才是隐藏的boss啊        22   125\n",
       "2      208215972               你到底说还是不说…        19     2\n",
       "3      208219537  中国朋友教了我一句话：无事献殷勤，非奸即盗。        47     3\n",
       "4      208237322     如果你是大学里唯一的美人鱼！潜伏技巧！     25907  6357\n",
       "...          ...                     ...       ...   ...\n",
       "74180  890997016                 吃我邪神酱飞T         2     1\n",
       "74181  890997066            《和暗恋女神的厕所之情》         0    78\n",
       "74182  890997085             串哥和秀文一起连麦选妃       116   275\n",
       "74183  890997096                 我又双叒叕来了         0     3\n",
       "74184  890997102           丈母娘啊，还是你最疼我啊！         0     3\n",
       "\n",
       "[74185 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "master = pd.read_csv('data/master.csv')             # 读取master信息文件\n",
    "master                                              # 展示部分数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "视频信息文件中各变量含义：\n",
    "\n",
    "* aid: 视频（图片）编号\n",
    "* title: 视频标题\n",
    "* follower: 发布者粉丝数\n",
    "* view: 视频播放量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制播放量直方图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "master['log_view'] = master['view'].apply(lambda x:np.log(x+1))          # 对播放量取对数，记为‘log_view’\n",
    "master['log_view'] = master['log_view']-np.mean(master['log_view'])      # 对播放量中心化\n",
    "master['log_view'] = master['log_view']/np.std(master['log_view'])       # 对播放量标准化\n",
    "\n",
    "plt.hist(master['log_view'])                                             # 对数标准化后播放量直方图\n",
    "plt.xlabel(\"log(view+1)\")                                                # 添加x轴标签\n",
    "plt.show()                                                               # 显示图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 图像数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们通过**迁移学习**提取图片特征。具体而言，通过迁移MobileNet模型并截断最后一层输出层，将每一个图片转换转换成1024维的特征X。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "dx=128;dy=128                                             #确定图片尺寸\n",
    "N = master.shape[0]                                       #全样本量\n",
    "n = 3*10**3                                               #教学需要，确定一个不要太大的样本量\n",
    "img_list=[]                                               #初始化一个list用于存储图像数据\n",
    "cap_list=[]                                               #初始化一个list用于存储图像的文字标注\n",
    "follower_list=[]                                          #初始化一个list用于存储粉丝数目\n",
    "view_list=[]                                              #初始化一个list用于存储播放量（对数标准化后）\n",
    "for i in range(n):\n",
    "    pos=np.random.randint(0,N)                            #随机抽取一个图片\n",
    "    cap_list.append(master.title[pos])                    #记录图片描述用文字\n",
    "    follower_list.append(np.log(1+master.follower[pos]))  #记录相关粉丝人数\n",
    "    view_list.append(master.log_view[pos])                #记录播放量\n",
    "    pic=master.aid[pos]                                   #被选中的图片的ID\n",
    "    Img=Image.open('data/Images/'+str(pic)+'.jpg')        #读入图像数据\n",
    "    img_list.append(np.array(Img.resize([dx,dy]))/255)    #记录选中的图片\n",
    "\n",
    "imgs=np.array(img_list)                                   #形成数组\n",
    "followers=np.array(follower_list).reshape([n,1])          #形成数组  \n",
    "views=np.array(view_list).reshape([n,1])                  #形成数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 07:17:18.662547: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-03 07:17:19.375070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15405 MB memory:  -> device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:1c:00.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_128_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 8s 0us/step\n",
      "17235968/17225924 [==============================] - 8s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 07:17:30.608994: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,BatchNormalization\n",
    "\n",
    "base_model = MobileNet( weights='imagenet',                                       # 加载经过训练的MobileNet模型的权重\n",
    "                        include_top=False,                                        # 不包含顶端\n",
    "                        input_shape=(dx, dy, 3))                                  # 输入图片的大小为 128*128*3\n",
    "x = base_model.output                                                             # 由迁移的MobileNet模型提取图片特征\n",
    "predict = GlobalAveragePooling2D()(x)                                             # 添加全局平均池化层\n",
    "model = Model(inputs=base_model.input, outputs=predict)                           # 构建需要训练的完整模型\n",
    "for layer in base_model.layers: layer.trainable = False                           # 锁住MobileNet的所有层（不进行训练）\n",
    "imgs=np.array(model(imgs))                                                        # 形成相关的X特征矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 文本数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于文字是非结构化数据，不能在计算机中直接分析，因此对文字进行编码处理。\n",
    "具体而言，使用Tokenizer建立分词器，根据词频，将每个文本转化为一个整数序列（每个整数都是词典中标记的索引），得到文本数组X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba                                 # 导入jieba包\n",
    "caps = []                                    # 新建一个空的列表，用于储存训练数据\n",
    "long_list=[]                                 # 创建一个特别长的list用于存储所有的分词结果\n",
    "for line in cap_list:                        # 遍历每一个标题\n",
    "    line_fenci = jieba.lcut(line)            # 对标题进行分词\n",
    "    caps.append(line_fenci)                  # 将分词后的结果添加到列表中\n",
    "    long_list=long_list+line_fenci           # 创建一个特别长的list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算各个关键词的频数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "skip_list=[',','!','：','《','》','!','?','(',')','，','【','】','（','）','！','？','，','。','#',' ','.']\n",
    "long_list=[each for each in long_list if each not in skip_list]\n",
    "long_list=[each for each in long_list if len(each)>1]\n",
    "tab=Counter(long_list)\n",
    "keys=[each[0] for each in tab.items() if int(each[1])>5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新整理标题描述文本的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_list_new=[]\n",
    "for each in caps: cap_list_new.append([kw for kw in each if kw in keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对新的文字关键词形成编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()                                            #产生一个分词器对象\n",
    "tokenizer.fit_on_texts(cap_list_new)                               #用标题的文本训练分词器\n",
    "cap_digit = tokenizer.texts_to_sequences(cap_list_new)             #将每个视频标题的文本转化为序列（列表类型）。每个字通过一个数值表示，每个视频标题的文本即变为这样数值的序列\n",
    "vocab_size = len(tokenizer.word_index) + 1                         #tokenizer.word_index为所有的词，len(tokenizer.word_index)为词的总个数。加上停止词0\n",
    "vocab_size                                                         #有多少个不同的词\n",
    "caps = pad_sequences(cap_digit, maxlen=6,padding='post')          #为了将所有的标题放在一个尺寸M*N的np.array中，将每一个视频的标题补0到同样的长度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 建立一个综合的LSTM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型1：全模型（图像+文本+粉丝数）\n",
    "\n",
    "对于模型1，我们的X为：图像特征，文本特征，以及粉丝数，Y为播放量。\n",
    "\n",
    "因此我们建立一个回归模型，建立模型后，进行模型编译和训练，这里我们选择的损失函数是'mse'，优化器是'adam'（学习率为0.001）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 6, 128)       39168       input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          131200      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 128)          131584      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          256         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128)          0           dense_6[0][0]                    \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            129         add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 302,337\n",
      "Trainable params: 302,337\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 9ms/step - loss: 22.3230 - mse: 22.3230\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 23.0356 - mse: 23.0356\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.1603 - mse: 7.1603\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 12.3851 - mse: 12.3851\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 5.0631 - mse: 5.0631\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6400 - mse: 6.6400\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.6223 - mse: 3.6223\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.0064 - mse: 4.0064\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.8467 - mse: 2.8467\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.6445 - mse: 2.6445\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.2576 - mse: 2.2576\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9139 - mse: 1.9139\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9101 - mse: 1.9101\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.4922 - mse: 1.4922\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5952 - mse: 1.5952\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2434 - mse: 1.2434\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3295 - mse: 1.3295\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1852 - mse: 1.1852\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1482 - mse: 1.1482\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1165 - mse: 1.1165\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0137 - mse: 1.0137\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0346 - mse: 1.0346\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9595 - mse: 0.9595\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9478 - mse: 0.9478\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9165 - mse: 0.9165\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8916 - mse: 0.8916\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8736 - mse: 0.8736\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8564 - mse: 0.8564\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8365 - mse: 0.8365\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8219 - mse: 0.8219\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8024 - mse: 0.8024\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7860 - mse: 0.7860\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7716 - mse: 0.7716\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7616 - mse: 0.7616\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7465 - mse: 0.7465\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7343 - mse: 0.7343\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7205 - mse: 0.7205\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7091 - mse: 0.7091\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6959 - mse: 0.6959\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6846 - mse: 0.6846\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6727 - mse: 0.6727\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6610 - mse: 0.6610\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6498 - mse: 0.6498\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6375 - mse: 0.6375\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6245 - mse: 0.6245\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6113 - mse: 0.6113\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5985 - mse: 0.5985\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5842 - mse: 0.5842\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5721 - mse: 0.5721\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5568 - mse: 0.5568\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5453 - mse: 0.5453\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5355 - mse: 0.5355\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5285 - mse: 0.5285\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5217 - mse: 0.5217\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5140 - mse: 0.5140\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5070 - mse: 0.5070\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5001 - mse: 0.5001\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4946 - mse: 0.4946\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4892 - mse: 0.4892\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4842 - mse: 0.4842\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4791 - mse: 0.4791\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4740 - mse: 0.4740\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4694 - mse: 0.4694\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4662 - mse: 0.4662\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4614 - mse: 0.4614\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4572 - mse: 0.4572\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4535 - mse: 0.4535\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4492 - mse: 0.4492\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4457 - mse: 0.4457\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4418 - mse: 0.4418\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4381 - mse: 0.4381\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4348 - mse: 0.4348\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4313 - mse: 0.4313\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4288 - mse: 0.4288\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4259 - mse: 0.4259\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4229 - mse: 0.4229\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4184 - mse: 0.4184\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4171 - mse: 0.4171\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4136 - mse: 0.4136\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4112 - mse: 0.4112\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4075 - mse: 0.4075\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4057 - mse: 0.4057\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4027 - mse: 0.4027\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4000 - mse: 0.4000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3986 - mse: 0.3986\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3961 - mse: 0.3961\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3930 - mse: 0.3930\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3900 - mse: 0.3900\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3875 - mse: 0.3875\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3857 - mse: 0.3857\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3836 - mse: 0.3836\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3831 - mse: 0.3831\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3831 - mse: 0.3831\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3790 - mse: 0.3790\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3780 - mse: 0.3780\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3756 - mse: 0.3756\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3712 - mse: 0.3712\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3688 - mse: 0.3688\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3661 - mse: 0.3661\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3648 - mse: 0.3648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7179f6eb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Activation, Reshape,add\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "dim_img=imgs.shape[1]                                                 #维度：图像数组\n",
    "dim_follower=1                                                        #维度：粉丝数目\n",
    "dim_cap=caps.shape[1]                                                 #维度：文字描述\n",
    "hidden_size = 128                                                     #指定模型中状态空间的维度\n",
    "\n",
    "inp_img = Input(shape=(dim_img,))                                     #输入层：图像特征向量\n",
    "inp_follower=Input(shape=(1,))                                        #输入层：粉丝数目\n",
    "inp_cap=Input(shape=(dim_cap,))                                       #输入层：描述文本\n",
    "x_img=Dense(hidden_size)(inp_img)                                     #模型处理：图像输入\n",
    "x_follower=Dense(hidden_size)(inp_follower)                           #模型处理：粉丝数目\n",
    "x = Embedding(vocab_size, hidden_size)(inp_cap)                       #模型处理：文本向量化\n",
    "x_cap = LSTM(hidden_size, return_sequences=False)(x)                  #加入一个LSTM网络\n",
    "x=add([x_img,x_cap,x_follower])                                       #整合不同的输入型号\n",
    "x=Dense(1)(x)                                                         #输出：预测最后的展现量\n",
    "model = Model([inp_img,inp_follower,inp_cap], x)                      #模型整合\n",
    "model.summary()                                                       #打印网络模型摘要表\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['mse'])           #设计优化方案\n",
    "model.fit([imgs,followers,caps], views, epochs=100, batch_size=1000)  #小批次样本量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型2：对比模型（文本+粉丝数）\n",
    "\n",
    "对于模型2，我们的X为：文本特征和粉丝数，Y为播放量。\n",
    "\n",
    "因此我们建立一个回归模型，建立模型后，进行模型编译和训练，这里我们选择的损失函数是'mse'，优化器是'adam'（学习率为0.001）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 6, 128)       39168       input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 128)          131584      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          256         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128)          0           lstm_3[0][0]                     \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            129         add_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 171,137\n",
      "Trainable params: 171,137\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 7ms/step - loss: 1.2884 - mse: 1.2884\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7091 - mse: 0.7091\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6656 - mse: 0.6656\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7574 - mse: 0.7574\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6767 - mse: 0.6767\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6126 - mse: 0.6126\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6182 - mse: 0.6182\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6326 - mse: 0.6326\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6150 - mse: 0.6150\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5857 - mse: 0.5857\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5774 - mse: 0.5774\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5825 - mse: 0.5825\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5755 - mse: 0.5755\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5646 - mse: 0.5646\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5645 - mse: 0.5645\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5624 - mse: 0.5624\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5550 - mse: 0.5550\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5499 - mse: 0.5499\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5461 - mse: 0.5461\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5388 - mse: 0.5388\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5334 - mse: 0.5334\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5272 - mse: 0.5272\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5195 - mse: 0.5195\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5148 - mse: 0.5148\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5103 - mse: 0.5103\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5084 - mse: 0.5084\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5064 - mse: 0.5064\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5036 - mse: 0.5036\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5012 - mse: 0.5012\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4994 - mse: 0.4994\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4979 - mse: 0.4979\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4967 - mse: 0.4967\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4958 - mse: 0.4958\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4951 - mse: 0.4951\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4949 - mse: 0.4949\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4932 - mse: 0.4932\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4927 - mse: 0.4927\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4921 - mse: 0.4921\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4916 - mse: 0.4916\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4908 - mse: 0.4908\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4901 - mse: 0.4901\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4896 - mse: 0.4896\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4890 - mse: 0.4890\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4884 - mse: 0.4884\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4883 - mse: 0.4883\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4875 - mse: 0.4875\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4866 - mse: 0.4866\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4858 - mse: 0.4858\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4855 - mse: 0.4855\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4843 - mse: 0.4843\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4841 - mse: 0.4841\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4829 - mse: 0.4829\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4821 - mse: 0.4821\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4807 - mse: 0.4807\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4802 - mse: 0.4802\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4793 - mse: 0.4793\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4773 - mse: 0.4773\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4768 - mse: 0.4768\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4759 - mse: 0.4759\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4745 - mse: 0.4745\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4735 - mse: 0.4735\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4724 - mse: 0.4724\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4716 - mse: 0.4716\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4696 - mse: 0.4696\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4685 - mse: 0.4685\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4672 - mse: 0.4672\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4661 - mse: 0.4661\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4655 - mse: 0.4655\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4645 - mse: 0.4645\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4628 - mse: 0.4628\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4627 - mse: 0.4627\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4607 - mse: 0.4607\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4600 - mse: 0.4600\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4590 - mse: 0.4590\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4581 - mse: 0.4581\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4575 - mse: 0.4575\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4568 - mse: 0.4568\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4565 - mse: 0.4565\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4549 - mse: 0.4549\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4560 - mse: 0.4560\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4526 - mse: 0.4526\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4532 - mse: 0.4532\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4512 - mse: 0.4512\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4509 - mse: 0.4509\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4497 - mse: 0.4497\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4490 - mse: 0.4490\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4482 - mse: 0.4482\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4470 - mse: 0.4470\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4478 - mse: 0.4478\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4459 - mse: 0.4459\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4451 - mse: 0.4451\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4456 - mse: 0.4456\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4435 - mse: 0.4435\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4447 - mse: 0.4447\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4425 - mse: 0.4425\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4416 - mse: 0.4416\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4412 - mse: 0.4412\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4408 - mse: 0.4408\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4393 - mse: 0.4393\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4394 - mse: 0.4394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7178f7d30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 128                                                     #指定模型中状态空间的维度\n",
    "inp_img = Input(shape=(dim_img,))                                     #输入层：图像特征向量\n",
    "inp_follower=Input(shape=(1,))                                        #输入层：粉丝数目\n",
    "inp_cap=Input(shape=(dim_cap,))                                       #输入层：描述文本\n",
    "x_img=Dense(hidden_size)(inp_img)                                     #模型处理：图像输入\n",
    "x_follower=Dense(hidden_size)(inp_follower)                           #模型处理：粉丝数目\n",
    "x = Embedding(vocab_size, hidden_size)(inp_cap)                       #模型处理：文本向量化\n",
    "x_cap = LSTM(hidden_size, return_sequences=False)(x)                  #加入一个LSTM网络\n",
    "x=add([x_cap,x_follower])                                             #整合不同的输入型号\n",
    "x=Dense(1)(x)                                                         #输出：预测最后的展现量\n",
    "model = Model([inp_follower,inp_cap], x)                              #模型整合\n",
    "model.summary()                                                       #打印网络模型摘要表\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['mse'])           #设计优化方案\n",
    "model.fit([followers,caps], views, epochs=100, batch_size=1000)       #小批次样本量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 模型3：对比模型（图像+文本）\n",
    "\n",
    "对于模型3，我们的X为：图像特征和文本特征，Y为播放量。\n",
    "\n",
    "因此我们建立一个回归模型，建立模型后，进行模型编译和训练，这里我们选择的损失函数是'mse'，优化器是'adam'（学习率为0.001）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 6, 128)       39168       input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          131200      input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 128)          131584      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128)          0           dense_12[0][0]                   \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            129         add_4[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 302,081\n",
      "Trainable params: 302,081\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 9ms/step - loss: 23.0827 - mse: 23.0827\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 24.1711 - mse: 24.1711\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.2119 - mse: 7.2119\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 13.0571 - mse: 13.0571\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 5.4834 - mse: 5.4834\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0824 - mse: 7.0824\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.0599 - mse: 4.0599\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.3388 - mse: 4.3388\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.1693 - mse: 3.1693\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.9568 - mse: 2.9568\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.5576 - mse: 2.5576\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.1992 - mse: 2.1992\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.1918 - mse: 2.1918\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7834 - mse: 1.7834\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9409 - mse: 1.9409\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5885 - mse: 1.5885\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.6909 - mse: 1.6909\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5181 - mse: 1.5181\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.4889 - mse: 1.4889\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.4627 - mse: 1.4627\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3879 - mse: 1.3879\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3812 - mse: 1.3812\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3301 - mse: 1.3301\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2902 - mse: 1.2902\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2808 - mse: 1.2808\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2313 - mse: 1.2313\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2262 - mse: 1.2262\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1957 - mse: 1.1957\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1679 - mse: 1.1679\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1595 - mse: 1.1595\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1333 - mse: 1.1333\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1097 - mse: 1.1097\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1012 - mse: 1.1012\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0806 - mse: 1.0806\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0546 - mse: 1.0546\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0431 - mse: 1.0431\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0195 - mse: 1.0195\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9935 - mse: 0.9935\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9755 - mse: 0.9755\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9442 - mse: 0.9442\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9140 - mse: 0.9140\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8855 - mse: 0.8855\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8658 - mse: 0.8658\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8522 - mse: 0.8522\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8378 - mse: 0.8378\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8208 - mse: 0.8208\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8104 - mse: 0.8104\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8003 - mse: 0.8003\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7903 - mse: 0.7903\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7800 - mse: 0.7800\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7713 - mse: 0.7713\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7636 - mse: 0.7636\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7581 - mse: 0.7581\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7468 - mse: 0.7468\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7395 - mse: 0.7395\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7348 - mse: 0.7348\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7248 - mse: 0.7248\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7174 - mse: 0.7174\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7105 - mse: 0.7105\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7043 - mse: 0.7043\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7014 - mse: 0.7014\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6954 - mse: 0.6954\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6909 - mse: 0.6909\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6900 - mse: 0.6900\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6833 - mse: 0.6833\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6733 - mse: 0.6733\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6708 - mse: 0.6708\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6630 - mse: 0.6630\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6594 - mse: 0.6594\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6507 - mse: 0.6507\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6487 - mse: 0.6487\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6421 - mse: 0.6421\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6355 - mse: 0.6355\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6317 - mse: 0.6317\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6283 - mse: 0.6283\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6225 - mse: 0.6225\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6181 - mse: 0.6181\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6140 - mse: 0.6140\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6096 - mse: 0.6096\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6057 - mse: 0.6057\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6016 - mse: 0.6016\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6016 - mse: 0.6016\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5965 - mse: 0.5965\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5894 - mse: 0.5894\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5848 - mse: 0.5848\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5831 - mse: 0.5831\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5770 - mse: 0.5770\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5733 - mse: 0.5733\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5703 - mse: 0.5703\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5667 - mse: 0.5667\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5610 - mse: 0.5610\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5590 - mse: 0.5590\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5531 - mse: 0.5531\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5487 - mse: 0.5487\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5444 - mse: 0.5444\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5425 - mse: 0.5425\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5381 - mse: 0.5381\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5325 - mse: 0.5325\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5285 - mse: 0.5285\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5240 - mse: 0.5240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7177869d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 128                                                     #指定模型中状态空间的维度\n",
    "inp_img = Input(shape=(dim_img,))                                     #输入层：图像特征向量\n",
    "inp_follower=Input(shape=(1,))                                        #输入层：粉丝数目\n",
    "inp_cap=Input(shape=(dim_cap,))                                       #输入层：描述文本\n",
    "x_img=Dense(hidden_size)(inp_img)                                     #模型处理：图像输入\n",
    "x_follower=Dense(hidden_size)(inp_follower)                           #模型处理：粉丝数目\n",
    "x = Embedding(vocab_size, hidden_size)(inp_cap)                       #模型处理：文本向量化\n",
    "x_cap = LSTM(hidden_size, return_sequences=False)(x)                  #加入一个LSTM网络\n",
    "x=add([x_img,x_cap])                                                  #整合不同的输入型号\n",
    "x=Dense(1)(x)                                                         #输出：预测最后的展现量\n",
    "model = Model([inp_img,inp_cap], x)                                   #模型整合\n",
    "model.summary()                                                       #打印网络模型摘要表\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['mse'])           #设计优化方案\n",
    "model.fit([imgs,caps], views, epochs=100, batch_size=1000)            #小批次样本量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型4：对比模型（图像+粉丝数）\n",
    "\n",
    "对于模型4，我们的X为：图像特征和粉丝数，Y为播放量。\n",
    "\n",
    "因此我们建立一个回归模型，建立模型后，进行模型编译和训练，这里我们选择的损失函数是'mse'，优化器是'adam'（学习率为0.001）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 128)          131200      input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          256         input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128)          0           dense_15[0][0]                   \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            129         add_5[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 131,585\n",
      "Trainable params: 131,585\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 24.3793 - mse: 24.3793\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 27.6212 - mse: 27.6212\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.9832 - mse: 8.9832\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 12.9189 - mse: 12.9189\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.4831 - mse: 7.4831\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.5304 - mse: 6.5304\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.4618 - mse: 5.4618\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.8119 - mse: 3.8119\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.0893 - mse: 4.0893\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.5850 - mse: 2.5850\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.1264 - mse: 3.1264\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8817 - mse: 1.8817\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.4203 - mse: 2.4203\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.7136 - mse: 1.7136\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.8612 - mse: 1.8612\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5814 - mse: 1.5814\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4816 - mse: 1.4816\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4657 - mse: 1.4657\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3080 - mse: 1.3080\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3167 - mse: 1.3167\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2352 - mse: 1.2352\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1750 - mse: 1.1750\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1625 - mse: 1.1625\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1039 - mse: 1.1039\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0825 - mse: 1.0825\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0528 - mse: 1.0528\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0220 - mse: 1.0220\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9981 - mse: 0.9981\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9757 - mse: 0.9757\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9545 - mse: 0.9545\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9308 - mse: 0.9308\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9120 - mse: 0.9120\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8927 - mse: 0.8927\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8755 - mse: 0.8755\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8580 - mse: 0.8580\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8427 - mse: 0.8427\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8271 - mse: 0.8271\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8130 - mse: 0.8130\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7985 - mse: 0.7985\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7855 - mse: 0.7855\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7728 - mse: 0.7728\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7601 - mse: 0.7601\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7482 - mse: 0.7482\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7374 - mse: 0.7374\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7279 - mse: 0.7279\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7177 - mse: 0.7177\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7065 - mse: 0.7065\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6983 - mse: 0.6983\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6864 - mse: 0.6864\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6797 - mse: 0.6797\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6692 - mse: 0.6692\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6602 - mse: 0.6602\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6539 - mse: 0.6539\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6465 - mse: 0.6465\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6395 - mse: 0.6395\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6307 - mse: 0.6307\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6235 - mse: 0.6235\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6167 - mse: 0.6167\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6090 - mse: 0.6090\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6023 - mse: 0.6023\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5959 - mse: 0.5959\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5930 - mse: 0.5930\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5859 - mse: 0.5859\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5800 - mse: 0.5800\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5738 - mse: 0.5738\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5706 - mse: 0.5706\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5633 - mse: 0.5633\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5577 - mse: 0.5577\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5526 - mse: 0.5526\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5501 - mse: 0.5501\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5458 - mse: 0.5458\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5400 - mse: 0.5400\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5357 - mse: 0.5357\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5316 - mse: 0.5316\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5273 - mse: 0.5273\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5234 - mse: 0.5234\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5190 - mse: 0.5190\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5143 - mse: 0.5143\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5108 - mse: 0.5108\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5080 - mse: 0.5080\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5041 - mse: 0.5041\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4998 - mse: 0.4998\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4973 - mse: 0.4973\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4935 - mse: 0.4935\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4908 - mse: 0.4908\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4877 - mse: 0.4877\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4849 - mse: 0.4849\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4815 - mse: 0.4815\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4787 - mse: 0.4787\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4764 - mse: 0.4764\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4735 - mse: 0.4735\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4711 - mse: 0.4711\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4692 - mse: 0.4692\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4671 - mse: 0.4671\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4640 - mse: 0.4640\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4619 - mse: 0.4619\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4593 - mse: 0.4593\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4570 - mse: 0.4570\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4557 - mse: 0.4557\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4539 - mse: 0.4539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7176e8ca0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 128                                                     #指定模型中状态空间的维度\n",
    "inp_img = Input(shape=(dim_img,))                                     #输入层：图像特征向量\n",
    "inp_follower=Input(shape=(1,))                                        #输入层：粉丝数目\n",
    "inp_cap=Input(shape=(dim_cap,))                                       #输入层：描述文本\n",
    "x_img=Dense(hidden_size)(inp_img)                                     #模型处理：图像输入\n",
    "x_follower=Dense(hidden_size)(inp_follower)                           #模型处理：粉丝数目\n",
    "x = Embedding(vocab_size, hidden_size)(inp_cap)                       #模型处理：文本向量化\n",
    "x_cap = LSTM(hidden_size, return_sequences=False)(x)                  #加入一个LSTM网络\n",
    "x=add([x_img,x_follower])                                             #整合不同的输入型号\n",
    "x=Dense(1)(x)                                                         #输出：预测最后的展现量\n",
    "model = Model([inp_img,inp_follower], x)                              #模型整合\n",
    "model.summary()                                                       #打印网络模型摘要表\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['mse'])           #设计优化方案\n",
    "model.fit([imgs,followers], views, epochs=100, batch_size=1000)       #小批次样本量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思考：如何做得更好？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
